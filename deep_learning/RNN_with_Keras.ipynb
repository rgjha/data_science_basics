{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd39881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniconda3 Python 3.10.9\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2aa9a27",
   "metadata": {},
   "source": [
    "There are three built-in RNN layers in Keras:\n",
    "\n",
    "-keras.layers.SimpleRNN, a fully-connected RNN where the output from previous timestep is to be fed to next timestep. \n",
    "\n",
    "-keras.layers.GRU, first proposed in Cho et al., 2014.\n",
    "\n",
    "-keras.layers.LSTM, first proposed in Hochreiter & Schmidhuber, 1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60cc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          64000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               98816     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d420140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 64)          64000     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 256)         247296    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65db3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 64)     64000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 64)     128000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " encoder (LSTM)                 [(None, 64),         33024       ['embedding_2[0][0]']            \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " decoder (LSTM)                 (None, 64)           33024       ['embedding_3[0][0]',            \n",
      "                                                                  'encoder[0][1]',                \n",
      "                                                                  'encoder[0][2]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           650         ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
    "    encoder_input\n",
    ")\n",
    "\n",
    "# Return states in addition to output\n",
    "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
    "    encoder_embedded\n",
    ")\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
    "    decoder_input\n",
    ")\n",
    "\n",
    "# Pass the 2 states to a new LSTM layer, as initial state\n",
    "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
    "    decoder_embedded, initial_state=encoder_state\n",
    ")\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "\n",
    "model = keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a773c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "\n",
    "# reset_states() will reset the cached state to the original initial_state.\n",
    "# If no initial_state was provided, zero-states will be used by default.\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba6ec870",
   "metadata": {},
   "source": [
    "Following: https://www.tensorflow.org/guide/keras/rnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional RNNs\n",
    "\n",
    "For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
    "\n",
    "Keras provides an easy API for you to build such bidirectional RNNs: the keras.layers.Bidirectional wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecdfd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 5, 128)           38400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
    ")\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33455713",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bcd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[5], y_train[5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "984f296d",
   "metadata": {},
   "source": [
    "When running on a machine with a NVIDIA GPU and CuDNN installed, the model built with CuDNN is much faster to train compared to the model that uses the regular TensorFlow kernel.\n",
    "\n",
    "The same CuDNN-enabled model can also be used to run inference in a CPU-only environment.\n",
    "\n",
    "We use this below. Wihtout it, it would have been much slower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1955fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 11s 11ms/step - loss: 0.9430 - accuracy: 0.6999 - val_loss: 0.5020 - val_accuracy: 0.8435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29c65abf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01118e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [2], target result is: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "    print(\n",
    "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
    "    )\n",
    "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68429dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
